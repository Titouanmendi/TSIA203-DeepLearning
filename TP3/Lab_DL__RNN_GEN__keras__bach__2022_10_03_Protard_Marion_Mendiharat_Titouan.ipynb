{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPOXHysXKGLW"
      },
      "source": [
        "# Lab Deep Learning/ Recurrent Neural Networks/ in keras\n",
        "\n",
        "## Training language model (Many-to-Many) and generating sequences (One-to-Many)\n",
        "\n",
        "**Author: geoffroy.peeters@telecom-paris.fr**\n",
        "\n",
        "**Version**:\n",
        "- 2022/06/15 (changed to tensorfow.keras, added translation of questions in EN)\n",
        "- 2022/10/03 (added ReLU, np_epoch=20)\n",
        "\n",
        "For any remark or suggestion, please feel free to contact me.\n",
        "\n",
        "\n",
        "## Objective:\n",
        "\n",
        "- We will train a network to learn a language model and then use it to generate new sequences.\n",
        "\n",
        "- Instead of training the language model on text-documents (as it is the case in most examples) we will train it to learn the language of the music of [Johann_Sebastian_Bach](https://en.wikipedia.org/wiki/Johann_Sebastian_Bach).\n",
        "For this, we will learn how J. S. Bach's \"Cello suite\" have been composed.\n",
        "Here is an example of a \"Cello suite\" [Link](https://www.youtube.com/watch?v=mGQLXRTl3Z0).\n",
        "\n",
        "- Rather than analyzing the audio signal, we use a symbolic representation of the \"Cello suite\" through their [MIDI files](https://en.wikipedia.org/wiki/MIDI#MIDI_files).\n",
        "  - A MIDI file encodes in a file, the set of musical notes, their duration, and intensity which have to be played by each instrument to \"render\" a musical piece. The \"rendering\" is usually operated by a MIDI synthesizer (such as VLC, QuickTime).\n",
        "\n",
        "- We will first train a language model on the whole set of MIDI files of the \"Cello suites\".\n",
        "- We will then sample this language model to create a new MIDI file which will be a brand new \"Cello suite\" composed by the computer.\n",
        "\n",
        "### Questions:\n",
        "\n",
        "In the bottom part of this lab, you will have to answer a set of questions. Answers to those only necessitates a couple of sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjlvVXvgbpbW"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IXocQU0HDntL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59ab24b-f6b7-4fa2-df9e-fec43fd317ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.22.4)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n",
            "Building wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592289 sha256=714aff03c0f18d187d39b6438372070fa5ed8c5cedf38434a5b5af6b8446dfd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.2.10 pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "! pip install pretty_midi\n",
        "\n",
        "import os\n",
        "import pretty_midi\n",
        "from scipy.io import wavfile\n",
        "import IPython\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Flatten, Dropout, Activation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "student = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6YQL6s5j93E"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_gZx9igIOvtU"
      },
      "outputs": [],
      "source": [
        "n_x = 79\n",
        "max_T_x = 1000\n",
        "sequence_length = 20\n",
        "T_y_generated = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgG1EmxKDhE5"
      },
      "source": [
        "## Collect data to create the language model\n",
        "\n",
        "We download the 36 MIDI files corresponding to the 36 \"Cello suites\" composed by J. S. Bach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C9Tgx3ooDgSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19d23cd-642a-4807-ab96-03400246b943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./cs4-4sar.mid', './cs5-3cou.mid', './cs6-4sar.mid', './cs1-4sar.mid', './cs2-2all.mid', './cs6-3cou.mid', './cs2-5men.mid', './cs2-1pre.mid', './cs3-1pre.mid', './cs3-4sar.mid', './cs6-2all.mid', './cs3-5bou.mid', './cs5-6gig.mid', './cs3-3cou.mid', './cs4-3cou.mid', './cs4-5bou.mid', './cs4-2all.mid', './cs5-1pre.mid', './cs5-5gav.mid', './cs1-2all.mid', './cs1-3cou.mid', './cs6-6gig.mid', './cs2-6gig.mid', './cs3-2all.mid', './cs3-6gig.mid', './cs5-2all.mid', './cs2-3cou.mid', './cs2-4sar.mid', './cs4-1pre.mid', './cs1-6gig.mid', './cs4-6gig.mid', './cs6-5gav.mid', './cs1-1pre.mid', './cs6-1pre.mid', './cs1-5men.mid', './cs5-4sar.mid']\n"
          ]
        }
      ],
      "source": [
        "DIR = './'\n",
        "import urllib.request\n",
        "midiFile_l = ['cs1-2all.mid', 'cs5-1pre.mid', 'cs4-1pre.mid', 'cs3-5bou.mid', 'cs1-4sar.mid', 'cs2-5men.mid', 'cs3-3cou.mid', 'cs2-3cou.mid', 'cs1-6gig.mid', 'cs6-4sar.mid', 'cs4-5bou.mid', 'cs4-3cou.mid', 'cs5-3cou.mid', 'cs6-5gav.mid', 'cs6-6gig.mid', 'cs6-2all.mid', 'cs2-1pre.mid', 'cs3-1pre.mid', 'cs3-6gig.mid', 'cs2-6gig.mid', 'cs2-4sar.mid', 'cs3-4sar.mid', 'cs1-5men.mid', 'cs1-3cou.mid', 'cs6-1pre.mid', 'cs2-2all.mid', 'cs3-2all.mid', 'cs1-1pre.mid', 'cs5-2all.mid', 'cs4-2all.mid', 'cs5-5gav.mid', 'cs4-6gig.mid', 'cs5-6gig.mid', 'cs5-4sar.mid', 'cs4-4sar.mid', 'cs6-3cou.mid']\n",
        "for midiFile in midiFile_l:\n",
        "  #if os.path.isfile(DIR + midiFile) is None:\n",
        "  urllib.request.urlretrieve (\"http://www.jsbach.net/midi/\" + midiFile, DIR + midiFile)\n",
        "nbExample = len(midiFile_l)\n",
        "\n",
        "midiFile_l = glob.glob(DIR + 'cs*.mid')\n",
        "print(midiFile_l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgCE_6urcVsj"
      },
      "source": [
        "## Read and convert all MIDI files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GEg5c8wfj93K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31af1304-bba7-4db0-816e-388f11dd997a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pitch: 58, start: 0.000000, end: 1.333333, duration: 1.333333\n",
            "pitch: 60, start: 1.333333, end: 2.666666, duration: 1.333333\n",
            "pitch: 61, start: 2.666666, end: 3.999999, duration: 1.333333\n",
            "pitch: 61, start: 3.999999, end: 4.999999, duration: 1.000000\n",
            "pitch: 58, start: 4.999999, end: 5.333332, duration: 0.333333\n",
            "pitch: 60, start: 5.333332, end: 6.999998, duration: 1.666666\n",
            "pitch: 58, start: 6.999998, end: 7.333331, duration: 0.333333\n",
            "pitch: 56, start: 7.333331, end: 7.666665, duration: 0.333333\n",
            "pitch: 55, start: 7.666665, end: 7.999998, duration: 0.333333\n",
            "pitch: 53, start: 7.999998, end: 9.333331, duration: 1.333333\n",
            "pitch: 55, start: 9.333331, end: 10.666664, duration: 1.333333\n",
            "pitch: 56, start: 10.666664, end: 11.999997, duration: 1.333333\n",
            "pitch: 56, start: 11.999997, end: 12.999997, duration: 1.000000\n",
            "pitch: 53, start: 12.999997, end: 13.333330, duration: 0.333333\n",
            "pitch: 55, start: 13.333330, end: 14.333330, duration: 1.000000\n",
            "pitch: 58, start: 14.333330, end: 14.666663, duration: 0.333333\n",
            "pitch: 51, start: 14.666663, end: 16.999996, duration: 2.333333\n",
            "pitch: 48, start: 16.999996, end: 17.333329, duration: 0.333333\n",
            "pitch: 50, start: 17.333329, end: 18.333329, duration: 1.000000\n",
            "pitch: 53, start: 18.333329, end: 18.666662, duration: 0.333333\n",
            "pitch: 56, start: 18.666662, end: 19.999995, duration: 1.333333\n",
            "pitch: 56, start: 19.999995, end: 20.999995, duration: 1.000000\n",
            "pitch: 53, start: 20.999995, end: 21.333328, duration: 0.333333\n",
            "pitch: 55, start: 21.333328, end: 22.333328, duration: 1.000000\n",
            "pitch: 58, start: 22.333328, end: 22.666661, duration: 0.333333\n",
            "pitch: 61, start: 22.666661, end: 24.999994, duration: 2.333333\n",
            "pitch: 58, start: 24.999994, end: 25.333327, duration: 0.333333\n",
            "pitch: 60, start: 25.333327, end: 26.333327, duration: 1.000000\n",
            "pitch: 64, start: 26.333327, end: 26.666660, duration: 0.333333\n",
            "pitch: 67, start: 26.666660, end: 27.999993, duration: 1.333333\n",
            "pitch: 58, start: 27.999993, end: 29.333326, duration: 1.333333\n",
            "pitch: 57, start: 29.333326, end: 30.333326, duration: 1.000000\n",
            "pitch: 55, start: 30.333326, end: 30.666659, duration: 0.333333\n",
            "pitch: 53, start: 30.666659, end: 31.666659, duration: 1.000000\n",
            "pitch: 51, start: 31.666659, end: 31.999992, duration: 0.333333\n",
            "pitch: 50, start: 31.999992, end: 33.333325, duration: 1.333333\n",
            "pitch: 51, start: 35.999991, end: 37.333324, duration: 1.333333\n",
            "pitch: 53, start: 39.999990, end: 41.333323, duration: 1.333333\n",
            "pitch: 58, start: 47.999988, end: 49.333321, duration: 1.333333\n",
            "pitch: 60, start: 49.333321, end: 50.666654, duration: 1.333333\n",
            "pitch: 61, start: 50.666654, end: 51.999987, duration: 1.333333\n",
            "pitch: 61, start: 51.999987, end: 52.999987, duration: 1.000000\n",
            "pitch: 58, start: 52.999987, end: 53.333320, duration: 0.333333\n",
            "pitch: 60, start: 53.333320, end: 54.999986, duration: 1.666666\n",
            "pitch: 58, start: 54.999986, end: 55.333319, duration: 0.333333\n",
            "pitch: 56, start: 55.333319, end: 55.666653, duration: 0.333333\n",
            "pitch: 55, start: 55.666653, end: 55.999986, duration: 0.333333\n",
            "pitch: 53, start: 55.999986, end: 57.333319, duration: 1.333333\n",
            "pitch: 55, start: 57.333319, end: 58.666652, duration: 1.333333\n",
            "pitch: 56, start: 58.666652, end: 59.999985, duration: 1.333333\n",
            "pitch: 56, start: 59.999985, end: 60.999985, duration: 1.000000\n",
            "pitch: 53, start: 60.999985, end: 61.333318, duration: 0.333333\n",
            "pitch: 55, start: 61.333318, end: 62.333318, duration: 1.000000\n",
            "pitch: 58, start: 62.333318, end: 62.666651, duration: 0.333333\n",
            "pitch: 51, start: 62.666651, end: 64.999984, duration: 2.333333\n",
            "pitch: 48, start: 64.999984, end: 65.333317, duration: 0.333333\n",
            "pitch: 50, start: 65.333317, end: 66.333317, duration: 1.000000\n",
            "pitch: 53, start: 66.333317, end: 66.666650, duration: 0.333333\n",
            "pitch: 56, start: 66.666650, end: 67.999983, duration: 1.333333\n",
            "pitch: 56, start: 67.999983, end: 68.999983, duration: 1.000000\n",
            "pitch: 53, start: 68.999983, end: 69.333316, duration: 0.333333\n",
            "pitch: 55, start: 69.333316, end: 70.333316, duration: 1.000000\n",
            "pitch: 58, start: 70.333316, end: 70.666649, duration: 0.333333\n",
            "pitch: 61, start: 70.666649, end: 72.999982, duration: 2.333333\n",
            "pitch: 58, start: 72.999982, end: 73.333315, duration: 0.333333\n",
            "pitch: 60, start: 73.333315, end: 74.333315, duration: 1.000000\n",
            "pitch: 64, start: 74.333315, end: 74.666648, duration: 0.333333\n",
            "pitch: 67, start: 74.666648, end: 75.999981, duration: 1.333333\n",
            "pitch: 58, start: 75.999981, end: 77.333314, duration: 1.333333\n",
            "pitch: 57, start: 77.333314, end: 78.333314, duration: 1.000000\n",
            "pitch: 55, start: 78.333314, end: 78.666647, duration: 0.333333\n",
            "pitch: 53, start: 78.666647, end: 79.666647, duration: 1.000000\n",
            "pitch: 51, start: 79.666647, end: 79.999980, duration: 0.333333\n",
            "pitch: 50, start: 79.999980, end: 81.333313, duration: 1.333333\n",
            "pitch: 51, start: 83.999979, end: 85.333312, duration: 1.333333\n",
            "pitch: 53, start: 87.999978, end: 89.333311, duration: 1.333333\n",
            "pitch: 53, start: 95.999976, end: 97.333309, duration: 1.333333\n",
            "pitch: 55, start: 97.333309, end: 98.666642, duration: 1.333333\n",
            "pitch: 56, start: 98.666642, end: 100.999975, duration: 2.333333\n",
            "pitch: 53, start: 100.999975, end: 101.333308, duration: 0.333333\n",
            "pitch: 55, start: 101.333308, end: 102.999974, duration: 1.666666\n",
            "pitch: 53, start: 102.999974, end: 103.333307, duration: 0.333333\n",
            "pitch: 51, start: 103.333307, end: 103.666641, duration: 0.333333\n",
            "pitch: 50, start: 103.666641, end: 103.999974, duration: 0.333333\n",
            "pitch: 63, start: 103.999974, end: 105.333307, duration: 1.333333\n",
            "pitch: 62, start: 105.333307, end: 106.666640, duration: 1.333333\n",
            "pitch: 60, start: 106.666640, end: 107.999973, duration: 1.333333\n",
            "pitch: 60, start: 107.999973, end: 108.999973, duration: 1.000000\n",
            "pitch: 57, start: 108.999973, end: 109.333306, duration: 0.333333\n",
            "pitch: 59, start: 109.333306, end: 110.333306, duration: 1.000000\n",
            "pitch: 62, start: 110.333306, end: 110.666639, duration: 0.333333\n",
            "pitch: 55, start: 110.666639, end: 111.666639, duration: 1.000000\n",
            "pitch: 53, start: 111.666639, end: 111.999972, duration: 0.333333\n",
            "pitch: 52, start: 111.999972, end: 113.333305, duration: 1.333333\n",
            "pitch: 53, start: 113.333305, end: 114.666638, duration: 1.333333\n",
            "pitch: 55, start: 114.666638, end: 115.999971, duration: 1.333333\n",
            "pitch: 56, start: 115.999971, end: 116.999971, duration: 1.000000\n",
            "pitch: 53, start: 116.999971, end: 117.333304, duration: 0.333333\n",
            "pitch: 50, start: 117.333304, end: 118.333304, duration: 1.000000\n",
            "pitch: 59, start: 118.333304, end: 118.666637, duration: 0.333333\n",
            "pitch: 60, start: 118.666637, end: 120.999970, duration: 2.333333\n",
            "pitch: 62, start: 120.999970, end: 121.333303, duration: 0.333333\n",
            "pitch: 62, start: 121.333303, end: 123.333303, duration: 2.000000\n",
            "pitch: 60, start: 123.333303, end: 123.999969, duration: 0.666666\n",
            "pitch: 60, start: 123.999969, end: 124.999969, duration: 1.000000\n",
            "pitch: 55, start: 124.999969, end: 125.333302, duration: 0.333333\n",
            "pitch: 51, start: 125.333302, end: 126.333302, duration: 1.000000\n",
            "pitch: 55, start: 126.333302, end: 126.666635, duration: 0.333333\n",
            "pitch: 48, start: 126.666635, end: 127.666635, duration: 1.000000\n",
            "pitch: 46, start: 127.666635, end: 127.999968, duration: 0.333333\n",
            "pitch: 45, start: 127.999968, end: 129.333301, duration: 1.333333\n",
            "pitch: 46, start: 131.999967, end: 133.333300, duration: 1.333333\n",
            "pitch: 39, start: 135.999966, end: 137.333299, duration: 1.333333\n",
            "pitch: 36, start: 138.666632, end: 139.999965, duration: 1.333333\n",
            "pitch: 44, start: 163.999959, end: 164.666625, duration: 0.666666\n",
            "pitch: 43, start: 167.999958, end: 168.666624, duration: 0.666666\n",
            "pitch: 44, start: 169.333291, end: 169.999957, duration: 0.666666\n",
            "pitch: 53, start: 175.999956, end: 177.333289, duration: 1.333333\n",
            "pitch: 55, start: 177.333289, end: 178.666622, duration: 1.333333\n",
            "pitch: 56, start: 178.666622, end: 180.999955, duration: 2.333333\n",
            "pitch: 53, start: 180.999955, end: 181.333288, duration: 0.333333\n",
            "pitch: 55, start: 181.333288, end: 182.999954, duration: 1.666666\n",
            "pitch: 53, start: 182.999954, end: 183.333287, duration: 0.333333\n",
            "pitch: 51, start: 183.333287, end: 183.666621, duration: 0.333333\n",
            "pitch: 50, start: 183.666621, end: 183.999954, duration: 0.333333\n",
            "pitch: 63, start: 183.999954, end: 185.333287, duration: 1.333333\n",
            "pitch: 62, start: 185.333287, end: 186.666620, duration: 1.333333\n",
            "pitch: 60, start: 186.666620, end: 187.999953, duration: 1.333333\n",
            "pitch: 60, start: 187.999953, end: 188.999953, duration: 1.000000\n",
            "pitch: 57, start: 188.999953, end: 189.333286, duration: 0.333333\n",
            "pitch: 59, start: 189.333286, end: 190.333286, duration: 1.000000\n",
            "pitch: 62, start: 190.333286, end: 190.666619, duration: 0.333333\n",
            "pitch: 55, start: 190.666619, end: 191.666619, duration: 1.000000\n",
            "pitch: 53, start: 191.666619, end: 191.999952, duration: 0.333333\n",
            "pitch: 52, start: 191.999952, end: 193.333285, duration: 1.333333\n",
            "pitch: 53, start: 193.333285, end: 194.666618, duration: 1.333333\n",
            "pitch: 55, start: 194.666618, end: 195.999951, duration: 1.333333\n",
            "pitch: 56, start: 195.999951, end: 196.999951, duration: 1.000000\n",
            "pitch: 53, start: 196.999951, end: 197.333284, duration: 0.333333\n",
            "pitch: 50, start: 197.333284, end: 198.333284, duration: 1.000000\n",
            "pitch: 59, start: 198.333284, end: 198.666617, duration: 0.333333\n",
            "pitch: 60, start: 198.666617, end: 200.999950, duration: 2.333333\n",
            "pitch: 62, start: 200.999950, end: 201.333283, duration: 0.333333\n",
            "pitch: 62, start: 201.333283, end: 203.333282, duration: 2.000000\n",
            "pitch: 60, start: 203.333282, end: 203.999949, duration: 0.666666\n",
            "pitch: 60, start: 203.999949, end: 204.999949, duration: 1.000000\n",
            "pitch: 55, start: 204.999949, end: 205.333282, duration: 0.333333\n",
            "pitch: 51, start: 205.333282, end: 206.333282, duration: 1.000000\n",
            "pitch: 55, start: 206.333282, end: 206.666615, duration: 0.333333\n",
            "pitch: 48, start: 206.666615, end: 207.666615, duration: 1.000000\n",
            "pitch: 46, start: 207.666615, end: 207.999948, duration: 0.333333\n",
            "pitch: 45, start: 207.999948, end: 209.333281, duration: 1.333333\n",
            "pitch: 46, start: 211.999947, end: 213.333280, duration: 1.333333\n",
            "pitch: 39, start: 215.999946, end: 217.333279, duration: 1.333333\n",
            "pitch: 36, start: 218.666612, end: 219.999945, duration: 1.333333\n",
            "pitch: 44, start: 243.999939, end: 244.666606, duration: 0.666667\n",
            "pitch: 43, start: 247.999938, end: 248.666604, duration: 0.666666\n",
            "pitch: 44, start: 249.333271, end: 249.999937, duration: 0.666666\n"
          ]
        }
      ],
      "source": [
        "# --- Read a single MIDI file\n",
        "midi_data = pretty_midi.PrettyMIDI(midiFile_l[0])\n",
        "# --- Display the note pitch, start, end and duration\n",
        "for note in midi_data.instruments[0].notes:\n",
        "    print('pitch: %d, start: %f, end: %f, duration: %f' % (note.pitch, note.start, note.end, note.end-note.start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDofyEKjcd4E"
      },
      "source": [
        "We read all MIDI files and convert their content to one-hot-encoding matrix X_ohe of dimensions (T_x, n_x) where n_x is the number of possible musical notes.\n",
        "The duration of the sequences T_x can vary from one sequence to the other.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EirVcbKxEe-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9287aaa0-2226-4f73-8568-785f4a939b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n",
            "(158, 79)\n",
            "(352, 79)\n",
            "(162, 79)\n"
          ]
        }
      ],
      "source": [
        "# --- We truncate the duration of each example to the first T_x data\n",
        "\n",
        "X_list = []\n",
        "\n",
        "for midiFile in midiFile_l:\n",
        "    # read the MIDI file\n",
        "    midi_data = pretty_midi.PrettyMIDI(midiFile)\n",
        "    note_l = [note.pitch for note in midi_data.instruments[0].notes]\n",
        "    # convert to one-hot-encoding\n",
        "    T_x = len(note_l)\n",
        "    if T_x > max_T_x:\n",
        "        T_x = max_T_x\n",
        "    X_ohe = np.zeros((T_x, n_x))\n",
        "    for t in range(T_x):\n",
        "        X_ohe[t, note_l[t]-1] = 1\n",
        "    # add to the list\n",
        "    X_list.append(X_ohe)\n",
        "\n",
        "print(len(X_list))\n",
        "print(X_list[0].shape)\n",
        "print(X_list[1].shape)\n",
        "print(X_list[2].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSf8RDL5cv7V"
      },
      "source": [
        "## Display the set of notes over time for a specific track"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wesPFMZHcvKG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "c41b2eb6-94b4-4494-8322-cf288478a63f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "plt.imshow(X_list[2].T, aspect='auto')\n",
        "plt.set_cmap('gray_r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMHtioR_c5y3"
      },
      "source": [
        "## Data conversion for the training of language model\n",
        "\n",
        "For each example/sequence and each possible starting note in this example/sequence, we create two sequences\n",
        "- an input sequence:\n",
        "  - which contains a sub-sequence of length ```sequence_length```;  this sub-sequence range from the note $t$ to the note $t+sequence\\_length-1$\n",
        "- an output sequence:\n",
        "  - which contains the following note to be predicted, the one at position $t+sequence\\_length$\n",
        "\n",
        "The training is therefore performed by giving to the model a set of sequences as input and asking the network to predict each time the note that should come right after this sequence.\n",
        "\n",
        "<img src=\"https://perso.telecom-paristech.fr/gpeeters/doc/Lab_DL_RNN_02.png\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EGzvp4RCC0XX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf23e84-ec12-4ffb-9e21-12e4681f5cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape: (23781, 20, 79)\n",
            "y_train.shape: (23781, 79)\n"
          ]
        }
      ],
      "source": [
        "X_train_list = []\n",
        "y_train_list = []\n",
        "\n",
        "if student:\n",
        "    # --- START CODE HERE (01)\n",
        "    for sequence in X_list:\n",
        "        for t in range(len(sequence) - sequence_length):\n",
        "            input_seq = sequence[t:t+sequence_length]\n",
        "            output_seq = sequence[t+sequence_length]\n",
        "            X_train_list.append(input_seq)\n",
        "            y_train_list.append(output_seq)\n",
        "    # --- END CODE HERE\n",
        "\n",
        "X_train = np.asarray(X_train_list)\n",
        "y_train = np.asarray(y_train_list)\n",
        "\n",
        "print(\"X_train.shape:\", X_train.shape)\n",
        "print(\"y_train.shape:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhNPrmvveuH3"
      },
      "source": [
        "# Training the language model\n",
        "\n",
        "The language model will be learned by training an RNN with input `X_train` and output `Y_train`:  for each of the examples of sequences, we give to the network a sequence of notes of `sequence_length` duration, and ask the network to predict the following note of each sequence.\n",
        "\n",
        "The network will have the following structure\n",
        "- (1a) a layer of `LSTM` with $n_a$=256\n",
        "- (1b) a layer of DropOut with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
        "- (2a) a layer of `LSTM` with $n_a$=256\n",
        "- (2b) a layer of DropOut with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
        "- (3) a layer of `LSTM` with $n_a$=256\n",
        "- (4a) a layer of `Dense` with 256 units and a `ReLU` activation\n",
        "- (4b) a layer of DropOut with rate 0.3 (the probability to \"drop-out\" one neuron is 0.3)\n",
        "- (5) a layer of `Dense` with a `softmax` activation which predict the probability of each of the $n_x$ notes as output\n",
        "\n",
        "## Returning the hidden states at each time of an LSTM cell\n",
        "\n",
        "Note that when we stack one LSTM layer on top of a second LSTM layer (deep-RNN), we need to tell the first LSTM to output its hidden states at each time $t$. This is done by the option `return_sequences=True` that has to be given as parameter to the LSTM on top of the other one.\n",
        "This is the case for (1a) and (2a).\n",
        "\n",
        "However, since we are only interrested in the last hidden state of the third LSTM (since we are only interrest in its prediction at time $T_x$), we give the option `return_sequences=False` (which is the default behaviour) for the third LSTM.\n",
        "This is the case for (3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "epWHM4p6D5n7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c146bf2-7f02-4a18-d7b6-0af1b4592ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 20, 256)           344064    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 256)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 20, 256)           525312    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20, 256)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 79)                20303     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,480,783\n",
            "Trainable params: 1,480,783\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# --- Create the model\n",
        "K.clear_session()\n",
        "\n",
        "na = 256  # Number of LSTM units\n",
        "\n",
        "if student:\n",
        "    # --- START CODE HERE (02)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(na, return_sequences=True, input_shape=(sequence_length, n_x)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(na, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(na, return_sequences=False))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_x, activation='softmax'))\n",
        "    # --- END CODE HERE\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yhWTNfIbFDmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f8b460-14cf-4a95-98e9-9a3fcc0b9d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "372/372 [==============================] - 19s 11ms/step - loss: 3.0356 - accuracy: 0.1001\n",
            "Epoch 2/20\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 2.6996 - accuracy: 0.1453\n",
            "Epoch 3/20\n",
            "372/372 [==============================] - 3s 9ms/step - loss: 2.5653 - accuracy: 0.1758\n",
            "Epoch 4/20\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 2.5087 - accuracy: 0.1969\n",
            "Epoch 5/20\n",
            "372/372 [==============================] - 4s 11ms/step - loss: 2.4540 - accuracy: 0.2350\n",
            "Epoch 6/20\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 2.3940 - accuracy: 0.2613\n",
            "Epoch 7/20\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 2.3441 - accuracy: 0.2816\n",
            "Epoch 8/20\n",
            "372/372 [==============================] - 4s 11ms/step - loss: 2.2898 - accuracy: 0.3002\n",
            "Epoch 9/20\n",
            "372/372 [==============================] - 4s 9ms/step - loss: 2.2296 - accuracy: 0.3228\n",
            "Epoch 10/20\n",
            "372/372 [==============================] - 3s 9ms/step - loss: 2.1676 - accuracy: 0.3388\n",
            "Epoch 11/20\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 2.0946 - accuracy: 0.3584\n",
            "Epoch 12/20\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 2.0168 - accuracy: 0.3794\n",
            "Epoch 13/20\n",
            "372/372 [==============================] - 3s 9ms/step - loss: 1.9305 - accuracy: 0.4049\n",
            "Epoch 14/20\n",
            "372/372 [==============================] - 4s 9ms/step - loss: 1.8303 - accuracy: 0.4300\n",
            "Epoch 15/20\n",
            "372/372 [==============================] - 4s 11ms/step - loss: 1.7226 - accuracy: 0.4621\n",
            "Epoch 16/20\n",
            "372/372 [==============================] - 3s 9ms/step - loss: 1.5925 - accuracy: 0.4977\n",
            "Epoch 17/20\n",
            "372/372 [==============================] - 3s 9ms/step - loss: 1.4705 - accuracy: 0.5290\n",
            "Epoch 18/20\n",
            "372/372 [==============================] - 4s 11ms/step - loss: 1.3440 - accuracy: 0.5685\n",
            "Epoch 19/20\n",
            "372/372 [==============================] - 4s 10ms/step - loss: 1.2192 - accuracy: 0.6076\n",
            "Epoch 20/20\n",
            "372/372 [==============================] - 3s 9ms/step - loss: 1.1036 - accuracy: 0.6427\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9a97a4250>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# --- Compile and fit the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM6g1YR3gtcO"
      },
      "source": [
        "# Generating a new sequence from sampling the language model\n",
        "\n",
        "To generate a new sequence from the language model, we simply give it as input a random sequence of duration ```sequence_length```and ask the trained network to predict the output (using ```model.predict```).\n",
        "\n",
        "The output of the network is a vector of probability of dimension $n_x$ which represents the probability of each note to be the next note of the melody given as input.\n",
        "\n",
        "From this vector, we select the note which has the maximum probability.\n",
        "\n",
        "We then concatenate this new note (its one-hot-encoding representation) at the end of the input sequence.\n",
        "We finally remove the first element of the input sequence to keep its duration constant (```sequence_length```).\n",
        "\n",
        "Instead of providing a random sequence as input, we rather randomly select one sequence out of the 23.781 sequences used for training.\n",
        "\n",
        "- The ```pattern``` variable is the ```list``` of init notes to which we progressively append the new generated notes by the model.\n",
        "- The ```prediction``` variable is a ```list``` which stores the softmax probability vector (a numpy array) corresponding to each generation time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_YHXTohsFGCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a019ff00-806b-42e1-ce34-fd84071c0d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3820\n",
            "(20, 79)\n",
            "(1, 20, 79)\n"
          ]
        }
      ],
      "source": [
        "# --- Select a random starting pattern\n",
        "start = np.random.randint(0, len(X_train_list)-1)\n",
        "pattern = X_train_list[start]\n",
        "print(start)\n",
        "print(pattern.shape)\n",
        "print(np.expand_dims(pattern, 0).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pattern.min())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld6zakEl-tvM",
        "outputId": "1c062738-fb81-427a-bdb5-d94dbf04fe20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f_ADCs7uFW8m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "a126e4e1-434a-462e-fd09-4c191ca0370a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 939ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8b326523ed42>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpredicted_note\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnote_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_note\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm' (type LSTM):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n"
          ]
        }
      ],
      "source": [
        "# --- note_l: is the list of notes (integer number) over time\n",
        "note_l = []\n",
        "# --- prediction_l: is the list of output-vectors (float numbers \\in [0,1]) of the network over time\n",
        "prediction_l = []\n",
        "# --- Generate T_y_generated notes\n",
        "for note_index in range(T_y_generated):\n",
        "    if student:\n",
        "        x = np.expand_dims(pattern, 0)\n",
        "        prediction = model.predict(x)[0]\n",
        "        predicted_note = np.argmax(prediction)\n",
        "        note_l.append(predicted_note)\n",
        "        prediction_l.append(prediction)\n",
        "        pattern = np.append(pattern[1:], predicted_note)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stQscvNOg0xd"
      },
      "source": [
        "### Display the generated sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9IOPPiuLuHE"
      },
      "outputs": [],
      "source": [
        "print(note_l)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.imshow(np.asarray(prediction_l)[:,0,:].T, aspect='auto', origin='lower')\n",
        "plt.plot(note_l)\n",
        "plt.set_cmap('gray_r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwM6osfDg5E0"
      },
      "source": [
        "### Create a MIDI file and an audio file which correspond to the generated sequence\n",
        "\n",
        "Once the new sequence has been generated (```note_l```) we transform it to a new MIDI file and perform (a very cheap) rendering of it in an audio file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cpTszOFID51"
      },
      "outputs": [],
      "source": [
        "new_midi_data = pretty_midi.PrettyMIDI()\n",
        "cello_program = pretty_midi.instrument_name_to_program('Cello')\n",
        "cello = pretty_midi.Instrument(program=cello_program)\n",
        "time = 0\n",
        "step = 0.3\n",
        "for note_number in note_l:\n",
        "    myNote = pretty_midi.Note(velocity=100, pitch=note_number, start=time, end=time+step)\n",
        "    cello.notes.append(myNote)\n",
        "    time += step\n",
        "new_midi_data.instruments.append(cello)\n",
        "new_midi_data.write('output.mid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOXBXxa3IGKW"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "audio_data = new_midi_data.synthesize(fs=44100)\n",
        "IPython.display.Audio(audio_data, rate=44100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb4DLCWjj93s"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "To evaluate the work, you should rate the code for\n",
        "- 1) Data conversion for the training of language model (01)\n",
        "- 2) Training the language model (02)\n",
        "- 3) Generating a new sequence from sampling the language model (03)\n",
        "\n",
        "You will also rate the answer to the four questions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgjoIxEqL7bx"
      },
      "source": [
        "## Question 1)\n",
        "\n",
        "What happens if we replace the LSTM cell by a RNNsimple cell?\n",
        "\n",
        "**Answer below** (1 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIstqiBzj93v"
      },
      "source": [
        "Answer: The RNNsimple cell can be a simpler and computationally efficient option, it may not be as effective as LSTM cells in capturing long-term dependencies and maintaining stable gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTB7qV8wj93y"
      },
      "source": [
        "## Question 2)\n",
        "\n",
        "What happens if we shorten the length of the sequences used for training? How can this effect be avoided?\n",
        "\n",
        "**Answer below** (1 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAuSUBH4j932"
      },
      "source": [
        "Answer: The model may not capture long-term dependencies and patterns in the data. This can result in lower accuracy and less coherent generated sequences.To avoid this, we could try to avoid having to shorten the length of sequences or use overlapping sequences so that each note in the original sequence will be part of multiple training examples. Doing so, we provide the model with more context and increase the chances of capturing long-term dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46IzXO5Wj935"
      },
      "source": [
        "## Question 3)\n",
        "\n",
        "How could we make the system polyphonic (several notes played simultaneously by the same instrument)? for training? for generation?\n",
        "\n",
        "**Answer below** (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAyxRPQoj937"
      },
      "source": [
        "Answer: For training, instead of representing the notes as a single value, we could use binary vectors to represent the presence or absence of each note at each time step. Each position in the vector corresponds to a specific note, and a value of 1 indicates that the note is played, while a value of 0 indicates that it is not played. Hence, we would also have to modify the inputs. They would now consist of a series of binary vectors representing the presence or absence of notes at each time step. The output sequences would also be binary vectors indicating the next set of notes to be played.\n",
        "\n",
        "For generation, instead of selecting a single note with the maximum probability at each time step, we could select multiple notes based on their probabilities. This can be done by sampling from the probability distribution or by considering the top-k notes with the highest probabilities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7MlNRsxj93-"
      },
      "source": [
        "## Question 4)\n",
        "\n",
        "We used a simplified procedure to train the musical language model, transforming the learning into a Many-To-one problem. Explain ? How does one usually train a language model with an RNN? What would be the advantage?\n",
        "\n",
        "**Answer below** (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJgs4uwpj94Q"
      },
      "source": [
        "Answer: Transforming the learning into Many-To-one problem allowed us to reduce the complexity of the training. This model takes an input sequence and predicts the corresponding output sequence, capturing dependencies and patterns in the data. Training with a Many-To-Many approach allows for more accurate predictions, considering the entire input sequence. However, the simplified Many-To-One approach used in the musical model sacrifices sequential information and context by predicting only the next note."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}